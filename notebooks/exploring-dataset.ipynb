{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "796ac5aa-fd59-4c94-a1a1-1bdca4a97fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized environment variables listed in: /mnt/workspace/__ing/llming/DTC/audio_podcast_qa_assistant/.env\n",
      "Initialized environment variables listed in: /mnt/workspace/__ing/llming/DTC/audio_podcast_qa_assistant/.env\n",
      "Connected to Elasticsearch\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## replace with root project dir\n",
    "PROJECT_DIR = \"/mnt/workspace/__ing/llming/DTC/audio_podcast_qa_assistant\"\n",
    "sys.path.append(PROJECT_DIR)\n",
    "\n",
    "from utils.utils import (\n",
    "    initialize_env_variables,\n",
    "    flatten_list_of_lists,\n",
    "    sample_from_list,\n",
    "    read_json_file,\n",
    "    save_json_file,\n",
    "    standardize_array,\n",
    ")\n",
    "\n",
    "initialize_env_variables()\n",
    "\n",
    "from utils.asr import (read_mp3, transcripe_episode)\n",
    "from utils.chunking import (chunk_large_text,\n",
    "                            preindex_process_text)\n",
    "from utils.questions import (extract_questions,\n",
    "                             group_questions_by_episode)\n",
    "# from utils.openai import create_openai_client\n",
    "from utils.query import openai_rephrase \n",
    "from utils.multithread import map_progress\n",
    "\n",
    "\n",
    "## HF_HOME\n",
    "cache_dir = os.path.join(PROJECT_DIR, \"hf_cache\")\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "130b8093-3f88-4c9b-bd74-4ec244d70ad7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/mohammed/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(os.getenv(\"HF_READING_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ac896ae-cc1e-43f4-815e-d51d2dc5b639",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380ae996f05e44bca08d76e5dccc30b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8745bac4575d4faaa1093bd9ce5aed15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the full lex fridman podcast dataset\n",
    "full_dataset = load_dataset(\n",
    "    path='Whispering-GPT/lex-fridman-podcast-transcript-audio', \n",
    "    cache_dir=cache_dir,\n",
    "    ignore_verifications=True,\n",
    ")['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75a183a-4205-4e26-8bdc-0a26fb43558a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75ad332f-dd56-4c96-b4f7-2433157fb85a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", cache_dir=cache_dir)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\", cache_dir=cache_dir)\n",
    "model.config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e23c7-8209-4400-90ba-fa0de74ec11c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f984fb826244dfac4995ca5942f4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/345 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = os.path.join(\n",
    "    PROJECT_DIR,\n",
    "    \"data/generated_transcriptions/\",\n",
    ")\n",
    "\n",
    "for i in tqdm(range(len(full_dataset))):\n",
    "    full_transcription = transcripe_episode(\n",
    "        episode=full_dataset['audio'][i],\n",
    "        processor=processor,\n",
    "        model=model,\n",
    "        skip_special_tokens=True,\n",
    "        minutes=0.4, ## due to model output constraint\n",
    "        target_sampling_rate=16_000,\n",
    "    )\n",
    "\n",
    "    path = os.path.join(\n",
    "        PROJECT_DIR,\n",
    "        \"data/generated_transcriptions/\",\n",
    "        f\"ep{i}.txt\"\n",
    "    )\n",
    "\n",
    "    with open(path, 'w', encoding=\"utf-8\") as file:\n",
    "        file.write(full_transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae373b9-a780-4b52-9d88-288c3f30a29b",
   "metadata": {},
   "source": [
    "Since this is very costly, we will rely on already present transcription."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eddc834-f5f5-496b-9bde-ec517ff1ae53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Chunking Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a5598b3-8fc4-43cf-a329-7840b359b83e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    full_dataset = full_dataset.remove_columns(['audio'])\n",
    "except ValueError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b793bf9-64f3-44ec-80c8-255142c938a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fd3fc09aed44109b9e30b95ba830c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "documents = map_progress(\n",
    "    f=lambda episode:preindex_process_text(\n",
    "        episode=episode, \n",
    "        chunking_function=chunk_large_text,\n",
    "        max_chunk_size=2000,\n",
    "    ),\n",
    "    seq=Dataset.from_list([full_dataset[0]]),\n",
    "    max_workers=4\n",
    ")\n",
    "documents = [item for sublist in documents for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a761b900-8415-4861-9dab-5764b2eb7fe3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped...\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(\n",
    "    PROJECT_DIR,\n",
    "    \"data/generated_documents/\",\n",
    "    \"documents.json\"\n",
    ")\n",
    "  \n",
    "save_json_file(documents, path, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62473643-15e0-4bbe-ad05-c722eb4a179f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Questions Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eced7797-d848-4fe7-91ae-74e169abb40c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    full_dataset = full_dataset.remove_columns(['audio'])\n",
    "except ValueError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3d5ca50-5c2a-4252-9619-4eb560a09ae2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "398d9e402bad4d3b923dac63714458ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/346 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "questions = map_progress(\n",
    "    f=lambda episode:extract_questions(\n",
    "        episode=episode,\n",
    "        min_words=15,\n",
    "    ),\n",
    "    seq=full_dataset,\n",
    "    max_workers=4\n",
    ")\n",
    "\n",
    "questions = flatten_list_of_lists(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e494c61-6069-4de6-bf5d-9a5188e6aaf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions before sampling: 3803\n",
      "Number of questions after sampling: 500\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of questions before sampling:\", len(questions))\n",
    "questions = sample_from_list(questions, sample_size=500, seed=42)\n",
    "print(\"Number of questions after sampling:\", len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b8e7cf4-d4c1-4bdd-8c5d-710811772910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Group questions by episode_id\n",
    "questions_per_episode = group_questions_by_episode(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca35b73-e95a-4707-ac82-94b1842afe72",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Openai rephrase questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dab8b3bb-9d88-4482-b1d2-9defa2711069",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5d850cc2a84965b1d7516a9269ae47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_template_path = os.path.join(PROJECT_DIR, \"prompts/rephrase_questions.txt\")\n",
    "\n",
    "rephrased_questions = map_progress(\n",
    "    f=lambda episode_questions:openai_rephrase(\n",
    "        episode_questions=episode_questions,\n",
    "        prompt_template_path=prompt_template_path,\n",
    "        model=\"gpt-4o-mini\",\n",
    "    ),\n",
    "    seq=questions_per_episode,\n",
    "    max_workers=4,\n",
    ")\n",
    "\n",
    "rephrased_questions = flatten_list_of_lists(rephrased_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd703c97-bdea-4fb7-87e3-cfb234428c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'episode_id': 'SFxIazwNP_0',\n",
       "  'question': 'When I take actions, am I the one doing it or is it just my atoms acting?'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_from_list(rephrased_questions, sample_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9994819a-947d-4cfb-bc0b-23d690803ba7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions after discarding non-self-sufficient: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of questions after discarding non-self-sufficient:\", len(rephrased_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2e69062-91cb-42db-9750-3a4abaac46e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped...\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(\n",
    "    PROJECT_DIR,\n",
    "    \"data/generated_questions/\",\n",
    "    \"questions.json\"\n",
    ")\n",
    "\n",
    "save_json_file(rephrased_questions, path, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d8c921-1d15-41f8-b9e1-aa718958eab4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Newly downloaded episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13dc70ac-00ce-4ec3-863b-ae7ea2b2f5a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    full_dataset = full_dataset.remove_columns(['audio'])\n",
    "except ValueError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70a78a26-40b5-456c-9820-6859cf985644",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Rate: 48000\n",
      "Audio Array Length: 417074688\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(PROJECT_DIR, \"bucket/351/lex_ai_mrbeast.mp3\")\n",
    "audio, sampling_rate = read_mp3(path)\n",
    "\n",
    "# mean=0, std=1\n",
    "audio = standardize_array(audio)\n",
    "\n",
    "print(\"Sampling Rate:\",sampling_rate)\n",
    "print(\"Audio Array Length:\",len(audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8afd5fd-7eaa-4a94-9ef4-e255c96f92ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode = {\n",
    "    'array': audio,\n",
    "    'sampling_rate': sampling_rate\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2385102-0549-4438-b1ab-f0223dc34c5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Transcribe then ask chatgpt to generate questions based on it\n",
    "## This will also happen in the pipeline (orchestration)\n",
    "path = os.path.join(\n",
    "    PROJECT_DIR,\n",
    "    \"data/generated_transcriptions/\",\n",
    "    \"lex_ai_mrbeast.txt\"\n",
    ")\n",
    "if not os.path.exists(path):\n",
    "    ep_transcription = transcripe_episode(\n",
    "        episode=episode,\n",
    "        processor=processor,\n",
    "        model=model,\n",
    "        skip_special_tokens=True,\n",
    "        minutes=0.4, ## due to model output constraint\n",
    "        target_sampling_rate=16_000,\n",
    "    )\n",
    "\n",
    "    with open(path, 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(ep_transcription)\n",
    "else:\n",
    "    with open(path, 'r') as f:\n",
    "        ep_transcription = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19462587-2e89-4e82-868e-ef4792e4c662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reading episode metadata (self-created):\n",
    "path = os.path.join(PROJECT_DIR, \"bucket/351/metadata.json\")\n",
    "episode = read_json_file(path)\n",
    "\n",
    "episode['text'] = ep_transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88ef988f-8e8b-4aab-bec4-7fd0d8978d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "document = preindex_process_text(\n",
    "    episode=episode, \n",
    "    chunking_function=chunk_large_text,\n",
    "    max_chunk_size=2000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f5bf2f-4aab-44b3-8228-b5fbdf2f8000",
   "metadata": {},
   "source": [
    "We can then reindex the newly created document..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 (dtc-llm-env)",
   "language": "python",
   "name": "dtc-llm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
