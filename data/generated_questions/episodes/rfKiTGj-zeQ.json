{
    "questions": [
        {
            "episode_id": "rfKiTGj-zeQ",
            "chunk_id": 18,
            "question": "What about the fact that maybe what we value is the up and down of life?"
        },
        {
            "episode_id": "rfKiTGj-zeQ",
            "chunk_id": 41,
            "question": "Is it at the very beginning, the assumption that everything stretches sort of infinite time essentially?"
        },
        {
            "episode_id": "rfKiTGj-zeQ",
            "chunk_id": 47,
            "question": "What are the chances out of these 200 trillion human that you should be human number 100 billion?"
        },
        {
            "episode_id": "rfKiTGj-zeQ",
            "chunk_id": 53,
            "question": "Do you have any kind of intuition about what Elon thinks about when he thinks about simulation?"
        },
        {
            "episode_id": "rfKiTGj-zeQ",
            "chunk_id": 61,
            "question": "Can you clarify just the two things we're talking about, the near-term and the long-term?"
        },
        {
            "episode_id": "rfKiTGj-zeQ",
            "chunk_id": 65,
            "question": "And just how explosive does something have to be for it to be called an intelligence explosion?"
        },
        {
            "episode_id": "rfKiTGj-zeQ",
            "chunk_id": 67,
            "question": "How much day to day would these super intelligences be involved in the lives of ordinary?"
        },
        {
            "episode_id": "rfKiTGj-zeQ",
            "chunk_id": 70,
            "question": "So if you were to pick a future, what do you think a utopia looks like with AGI systems?"
        },
        {
            "episode_id": "rfKiTGj-zeQ",
            "chunk_id": 74,
            "question": "You can always come up with values that are exactly opposed to one another, right?"
        }
    ]
}